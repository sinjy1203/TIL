{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6be2da5",
   "metadata": {},
   "source": [
    "## 텍스트 요약\n",
    "\n",
    "### 추출적 요약\n",
    "- 원문에서 핵심 문장또는 단어구를 뽑아서 구성된 요약문\\\n",
    "    => 모델의 언어 표현 능력 제한 ex)TextRank\n",
    "    \n",
    "### 추상적 요약\n",
    "- 핵심 문맥을 반영한 새로운 문장 생성\\\n",
    "    => 난이도 업, 요약 레이블 필요 ex) seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357fee7",
   "metadata": {},
   "source": [
    "# 어텐션을 이용한 텍스트 요약 (Text Summarization with Attention mechanism)\n",
    "- 추상적 요약\n",
    "- 큰 원문을 핵심 내용만 간추려서 작은 요약문으로 변환\n",
    "- 모델 구조는 인코더 디코더 각각은 RNN모델을 사용하고 디코더의 마지막 층에 어텐션 층을 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6d6e2",
   "metadata": {},
   "source": [
    "# 문장 임베딩 기반 텍스트 랭크 (TextRank Based on Sentence Embedding)\n",
    "- 추출적 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20a8c3",
   "metadata": {},
   "source": [
    "## 텍스트 랭크 (TextRank)\n",
    "- 그래프의 노드는 문장, 간선의 가중치는 문장들 간에 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b9329",
   "metadata": {},
   "source": [
    "## 사전 훈련된 임베딩\n",
    "- 사전 훈련된 임베딩으로 워드 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c45dc",
   "metadata": {},
   "source": [
    "## 문장 임베딩\n",
    "- 문장을 표현하는 고정된 길이의 벡터로 표현\n",
    "    => ex) 각 워드 임베딩 벡터들의 평균을 문장임베딩 벡터로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea61f6f",
   "metadata": {},
   "source": [
    "## 수행과정\n",
    "1. 각 문서의 문장임베딩 간에 코사인 유사도를 구한다.\n",
    "2. 각 문서의 유사도 행렬을 이용해 랭크알고리즘을 이용해 각 문장의 score을 구한다.\n",
    "3. top-n개를 선택하여 요약문으로 삼는다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
